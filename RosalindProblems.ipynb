{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from Bio import Seq\n",
    "import urllib\n",
    "from Bio import Entrez\n",
    "#also set email address needed for using entrez\n",
    "Entrez.email = 'jennala1487@gmail.com'\n",
    "from Bio import SeqIO\n",
    "import statistics as stat\n",
    "from Bio.Seq import translate\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to proper working directory- used for reading and writing all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/jenna/OneDrive/Desktop/Rosalind\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/c/Users/jenna/OneDrive/Desktop/Rosalind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Count the number of each nt in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in string\n",
    "filepath=\"seq2.txt\"\n",
    "seq = open(filepath, 'r').read().replace('\\n', '')\n",
    "    \n",
    "#Print out the number of times each occurs\n",
    "counts=[seq.count(\"A\"), seq.count(\"C\"), seq.count(\"G\"), seq.count(\"T\")]\n",
    "print(\"Occurences of A/C/G/T:\")\n",
    "\" \".join(map(str, counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Given a protein's ID, retrieve a list of biological processes it's involved in from UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in id\n",
    "id=open(\"rosalind_ini.txt\").read()\n",
    "\n",
    "#get url for id\n",
    "url=\"http://www.uniprot.org/uniprot/\"+ id + \".txt\"\n",
    "\n",
    "#open up url\n",
    "content=urllib.request.urlopen(url) \n",
    "\n",
    "#iterate through each line, saving lines with \"GO\", then split up to print just the process names\n",
    "print(\"GO terms for given protein id:\")\n",
    "for line in content: \n",
    "    line=str(line)\n",
    "    if \"GO\" in line:\n",
    "        groups=line.split(\";\")\n",
    "        group2=\";\".join(groups[2:3])\n",
    "        print(group2.split(\":\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: given a genus name and a range of dates, return the number of entries in Nucleotide GenBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in search terms\n",
    "filepath=\"rosalind_gbk.txt\"\n",
    "searchList=open(filepath,'r').read().split(\"\\n\")\n",
    "\n",
    "#assign to name. Assumes in format of genus \\n start date \\n end date\n",
    "genus=searchList[0]\n",
    "firstdate=searchList[1]\n",
    "seconddate=searchList[2]\n",
    "\n",
    "#get query to use\n",
    "query= f'({genus}[Organism]) AND(\"{firstdate}\"[Publication Date]: \"{seconddate}\"[Publication Date])'\n",
    "\n",
    "#get the handle for the given organism\n",
    "handle = Entrez.esearch(db=\"nucleotide\", term=query)\n",
    "\n",
    "#read record of the handle, print out the count\n",
    "record = Entrez.read(handle)\n",
    "print(\"Number of records for genus in given time frame: \" + record[\"Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: given list of genbank gene IDs, return the fasta file of the gene with the shortest header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in IDs\n",
    "wd= \"/mnt/c/Users/jenna/OneDrive/Desktop/Rosalind/\"\n",
    "filepath=wd+\"rosalind_frmt.txt\"\n",
    "IDs=open(filepath).read().replace(\"\\n\", \"\").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the handle for the given IDs, returning fasta data\n",
    "handle = Entrez.efetch(db=\"nucleotide\", id=IDs, rettype=\"fasta\")\n",
    "\n",
    "#use SeqIO to read in record as fasta format\n",
    "records = list (SeqIO.parse(handle, \"fasta\")) \n",
    "\n",
    "#get index of fasta with shortest description\n",
    "lengths=[]\n",
    "\n",
    "for record in records:\n",
    "    lengths.append(len(record.seq))\n",
    "    \n",
    "minIndex=lengths.index(min(lengths))\n",
    "\n",
    "#Print out this fasta record\n",
    "print(records[minIndex].format(\"fasta\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: given a file with fastqs, convert to fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get path to string\n",
    "wd= \"/mnt/c/Users/jenna/OneDrive/Desktop/Rosalind/\"\n",
    "filepath=wd+\"rosalind_tfsq.txt\"\n",
    "\n",
    "#write out to fasta\n",
    "SeqIO.convert(filepath,'fastq','test.fasta.txt','fasta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: given a file with fastqs + quality threshold, print the number of fastqs that pass that threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in fastq as normal text, extract threshold\n",
    "file=\"rosalind_phre.txt\"\n",
    "fileSplit=open(wd+file).read().split(\"\\n\")\n",
    "thresh=int(fileSplit[0])\n",
    "\n",
    "#remove first line (threshold) from fastq, then write back out as same file\n",
    "with open(file, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(file, 'w') as fout:\n",
    "    fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize count, then count the number of fastqs with a mean quality score less than the given threshold\n",
    "count=0\n",
    "for record in list(SeqIO.parse(file, \"fastq\")):\n",
    "    avgQ=stat.mean(record.letter_annotations[\"phred_quality\"])\n",
    "    if avgQ<thresh:\n",
    "        count=count+1\n",
    "print(str(count) + \" fastqs have a mean quality score less than \" + str(thresh))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7: given a file with fastqs + quality threshold + % of bases that need to meet that theshold, print the number of fastqs that pass that threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in fastq as normal text, extract quality threshold and percentage threshold\n",
    "file=\"rosalind_bphr.txt\"\n",
    "fileSplit=open(file).read().split(\"\\n\")\n",
    "\n",
    "ScoreThresh=int(fileSplit[0].split(\" \")[0])\n",
    "\n",
    "#remove first line (threshold) from fastq, then write back out as same file\n",
    "with open(file, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(file, 'w') as fout:\n",
    "    fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 positions have a mean quality below 24\n"
     ]
    }
   ],
   "source": [
    "#Initialize count list\n",
    "positions=[]\n",
    "nRecords=0\n",
    "LowScores=[]\n",
    "\n",
    "#For every position across all fastqs, get the score. Add all scores at that position together\n",
    "for record in list(SeqIO.parse(file, \"fastq\")):\n",
    "    nRecords+=1\n",
    "    q=record.letter_annotations[\"phred_quality\"]\n",
    "    for score in range(0,len(q)):\n",
    "        try:\n",
    "            positions[score]+= q[score]\n",
    "        except:\n",
    "            positions.append(q[score])\n",
    "\n",
    "#for each position, get the mean score across all fastqs, test if greater than given threshold\n",
    "for position in positions:\n",
    "    MeanQual=position/nRecords\n",
    "    if MeanQual<ScoreThresh:\n",
    "        LowScores.append(MeanQual)\n",
    "        \n",
    "print(str(len(LowScores)) + \" positions have a mean quality below \" + str(ScoreThresh))        \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8: given a file with fastqs + quality threshold, trim bases from the beginning and end that don't meet that quality threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in fastq as normal text, extract quality threshold and percentage threshold\n",
    "file=\"rosalind_bfil.txt\"\n",
    "fileSplit=open(file).read().split(\"\\n\")\n",
    "\n",
    "ScoreThresh=int(fileSplit[0].split(\" \")[0])\n",
    "\n",
    "#remove first line (threshold) from fastq, then write back out as same file\n",
    "with open(file, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(file, 'w') as fout:\n",
    "    fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize count list + file to write out\n",
    "nRecords=0\n",
    "myfile = open('TrimmedFastqs.txt', 'w')\n",
    "\n",
    "#get list of scores for all records\n",
    "for record in list(SeqIO.parse(file, \"fastq\")):\n",
    "    nRecords+=1\n",
    "    q=record.letter_annotations[\"phred_quality\"]\n",
    "    \n",
    "    #for each record, get positions from START that are less than threshold. Break once you hit a high qual position\n",
    "    lowQualStart=[]\n",
    "    for i in range(len(q)):\n",
    "        qual=q[i]\n",
    "        if qual<ScoreThresh:\n",
    "            lowQualStart.append(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    #for each record, get positions from END that are less than threshold. Break once you hit a high qual position\n",
    "    lowQualEnd=[]\n",
    "    for i in reversed(range(len(q))):\n",
    "        qual=q[i]\n",
    "        if qual<ScoreThresh:\n",
    "            lowQualEnd.append(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    #bind low qual start/end indexes together, remove from seqs\n",
    "    trim=[lowQualStart, lowQualEnd]\n",
    "    trim=list(chain.from_iterable(trim))\n",
    "    remove=list(set(list(range(0,len(q))))-set(trim))\n",
    "    record_removed=record[min(remove):(max(remove)+1)]\n",
    "    myfile.write(record_removed.format(\"fastq\"))\n",
    "    \n",
    "myfile.close()    \n",
    "       \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9: for a file containing two genbank IDs, get alignment score using Needle for fasta sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in IDs, export fasta files\n",
    "filepath=\"rosalind_need.txt\"\n",
    "IDs=open(filepath).read().replace(\"\\n\", \"\").split(\" \")\n",
    "\n",
    "#get the handle for the given IDs, returning fasta data\n",
    "handle = Entrez.efetch(db=\"nucleotide\", id=IDs, rettype=\"fasta\")\n",
    "\n",
    "#use SeqIO to read in record as fasta format\n",
    "records = list (SeqIO.parse(handle, \"fasta\")) \n",
    "\n",
    "#write out fasta to file\n",
    "for record in records:\n",
    "    filename=record.id + \".txt\"\n",
    "    myfile=open(filename, \"w\")\n",
    "    myfile.write(record.format(\"fasta\"))\n",
    "    myfile.close()    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NM_002124.3.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execute needle at command line: needle file1.txt file2.txt -endweight -endopen 10 -endextend 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10: for an input DNA and aa sequence it translates to, print the codon table (1=standard, other options are 2-15) that was used to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in DNA and aa sequence\n",
    "filepath=\"rosalind_ptra.txt\"\n",
    "both=open(filepath).read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no table for number 7\n",
      "no table for number 8\n",
      "Codon table 12 used to translate the DNA sequence\n"
     ]
    }
   ],
   "source": [
    "#Cycle through all possible codon tables- 1-15, with at least 7-8 now deleted. Check which (may be multiple) would result in the given aa sequence\n",
    "for i in range(1,16):\n",
    "    try:\n",
    "        translated=translate(both[0], table =i, stop_symbol=\"\")\n",
    "        if translated == both[1]:\n",
    "            print(\"Codon table \" + str(i) + \" used to translate the DNA sequence\")\n",
    "    except:\n",
    "        print(\"no table for number \" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11: for a list of DNA sequence, print how many match their own reverse complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the dna sequences\n",
    "filepath=\"rosalind_rvco.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 sequences match their reverse complement\n"
     ]
    }
   ],
   "source": [
    "#initialize count variable\n",
    "count=0\n",
    "\n",
    "#loop through all entries, check if their RC matches the forward seq\n",
    "for record in list(SeqIO.parse(filepath, \"fasta\")):\n",
    "    seq=record.seq\n",
    "    rc=seq.reverse_complement()\n",
    "    if seq == rc:\n",
    "        count+=1\n",
    "print(str(count) + \" sequences match their reverse complement\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12: For a given DNA string, get the longest open reading frame (all frames, forward and reverse considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKHNS\n",
      "MTVPRSRPGPALGGVNIPSWTRGTYTEYVCWKVPYNFDTQTGVSTIGEKGPI\n",
      "MTLR\n",
      "MHPPLGPLGRRPRAT\n",
      "MGG\n",
      "MVTSSGVGSAPQVCHDQLL\n",
      "MTSCFK\n",
      "MPGASRCG\n",
      "MG\n",
      "MINL\n",
      "MTVPRSRPGPALGGVNIPSWTRGTYTEYVCWKVPYNFDTQTGVSTIGEKGPI is the longest ORF\n"
     ]
    }
   ],
   "source": [
    "#read in sequence\n",
    "seq=open(\"rosalind_orfr.txt\").read().replace(\"\\n\", \"\")\n",
    "\n",
    "#initialize dictionary for adding ORFs\n",
    "lengths={}\n",
    "\n",
    "#for every ORF, translate. Add to dictionary if aa sequence starts with \"M\"\n",
    "for nt in range(0,len(seq)):\n",
    "    orf=Seq(seq[nt:])\n",
    "    translated=translate(orf, to_stop=True,table=1)\n",
    "    aaStr=str(translated)\n",
    "    if len(aaStr)>0:\n",
    "        if aaStr[0]==\"M\":\n",
    "            print(aaStr)\n",
    "            lengths[len(aaStr)]=aaStr\n",
    "\n",
    "\n",
    "#take reverse complement of input sequence before looping through all ORFs and translating\n",
    "rc=str(Seq(seq).reverse_complement())\n",
    "for nt in range(0,len(rc)):\n",
    "    orf=Seq(rc[nt:])\n",
    "    translated=translate(orf, to_stop=True,table=1)\n",
    "    aaStr=str(translated)\n",
    "    if len(aaStr)>0:\n",
    "        if aaStr[0]==\"M\":\n",
    "            lengths[len(aaStr)]=aaStr\n",
    "    \n",
    "\n",
    "print(lengths[max(lengths)] + \" is the longest ORF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
